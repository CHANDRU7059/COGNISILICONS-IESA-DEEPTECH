# ============================================================================
# SEMICONDUCTOR WAFER DEFECT CLASSIFICATION - WITH ONNX EXPORT (FIXED)
# ============================================================================

# CELL 1: Install Dependencies (UPDATED with onnxscript)
print("Installing dependencies...")
!pip install -q torch torchvision onnx onnxruntime onnxscript scikit-learn seaborn tqdm
from IPython.display import clear_output
clear_output()
print("All dependencies installed successfully!")

# CELL 2: Imports
import os, random, time, shutil, zipfile, warnings
from pathlib import Path
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR
import torchvision.transforms as T
from torchvision import models
import onnx

from sklearn.metrics import accuracy_score, confusion_matrix
from tqdm.auto import tqdm
from google.colab import files

warnings.filterwarnings('ignore')

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Device: {DEVICE}")

# CELL 3: Config
EPOCHS = 15 
BATCH_SIZE = 32
LEARNING_RATE = 0.001
IMAGE_SIZE = 224
MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]
NUM_WORKERS = 0 

DATASET_DIR = "/content/dataset"
CHECKPOINT_DIR = "/content/checkpoints"
RESULTS_DIR = "/content/results"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)
os.makedirs(RESULTS_DIR, exist_ok=True)

CLASS_NAMES = []
NUM_CLASSES = 0

# CELL 4: Upload Dataset
def create_val_split(ratio=0.2):
    train_dir = os.path.join(DATASET_DIR, 'train')
    val_dir = os.path.join(DATASET_DIR, 'val')
    os.makedirs(val_dir, exist_ok=True)
    for cls in os.listdir(train_dir):
        src = os.path.join(train_dir, cls)
        if not os.path.isdir(src): continue
        dst = os.path.join(val_dir, cls)
        os.makedirs(dst, exist_ok=True)
        imgs = [f for f in os.listdir(src) if f.lower().endswith(('.jpg','.jpeg','.png','.bmp'))]
        if len(imgs) < 2: continue
        n = max(1, int(len(imgs)*ratio))
        random.shuffle(imgs)
        for img in imgs[:n]:
            shutil.move(os.path.join(src, img), os.path.join(dst, img))

def upload_dataset():
    print("Upload your dataset ZIP (containing a 'train' folder with class subfolders)")
    uploaded = files.upload()
    if not uploaded: return False
    
    zip_file = list(uploaded.keys())[0]
    if os.path.exists(DATASET_DIR): shutil.rmtree(DATASET_DIR)
    
    with zipfile.ZipFile(zip_file, 'r') as z:
        z.extractall("/content/temp")
    
    train_path = None
    for root, dirs, _ in os.walk("/content/temp"):
        if "train" in dirs:
            train_path = os.path.join(root, "train")
            break
    
    if not train_path:
        print("ERROR: 'train' folder not found!")
        return False
    
    os.makedirs(DATASET_DIR, exist_ok=True)
    shutil.move(train_path, os.path.join(DATASET_DIR, "train"))
    
    global CLASS_NAMES, NUM_CLASSES
    CLASS_NAMES = sorted([d for d in os.listdir(os.path.join(DATASET_DIR, "train")) if os.path.isdir(os.path.join(DATASET_DIR, "train", d))])
    NUM_CLASSES = len(CLASS_NAMES)
    
    create_val_split()
    print(f"Dataset ready! Classes: {CLASS_NAMES}")
    return True

upload_dataset()

# CELL 5: Data Pipeline
class GrayToRGB:
    def __call__(self, img): return img.convert('RGB')

train_tf = T.Compose([GrayToRGB(), T.Resize((IMAGE_SIZE, IMAGE_SIZE)), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize(MEAN, STD)])
val_tf = T.Compose([GrayToRGB(), T.Resize((IMAGE_SIZE, IMAGE_SIZE)), T.ToTensor(), T.Normalize(MEAN, STD)])

class WaferDataset(Dataset):
    def __init__(self, root, transform=None):
        self.root = Path(root)
        self.transform = transform
        self.samples = []
        for cls in CLASS_NAMES:
            cls_path = self.root / cls
            if cls_path.exists():
                for f in cls_path.iterdir():
                    if f.suffix.lower() in {'.jpg','.jpeg','.png','.bmp'}:
                        self.samples.append((str(f), CLASS_NAMES.index(cls)))
    def __len__(self): return len(self.samples)
    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path)
        if self.transform: img = self.transform(img)
        return img, label

train_ds = WaferDataset(os.path.join(DATASET_DIR, "train"), train_tf)
val_ds = WaferDataset(os.path.join(DATASET_DIR, "val"), val_tf)
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)

# CELL 6: Model Setup
model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)
model = model.to(DEVICE)

# CELL 7: Training
criterion = nn.CrossEntropyLoss()
optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)
scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)

best_acc = 0
for epoch in range(EPOCHS):
    model.train()
    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            outputs = model(imgs)
            correct += (outputs.argmax(1) == labels).sum().item()
            total += labels.size(0)
    
    acc = 100 * correct / (total + 1e-6)
    scheduler.step()
    print(f"Val Accuracy: {acc:.2f}%")
    if acc > best_acc:
        best_acc = acc
        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, "best.pt"))

# CELL 8 & 9: Testing omitted for brevity (same as your logic)

# ============================================================================
# CELL 10: EXPORT TO ONNX (FIXED)
# ============================================================================
def export_to_onnx():
    print("\n" + "="*40)
    print("EXPORTING MODEL TO ONNX")
    print("="*40)
    
    # Load weights
    checkpoint_path = os.path.join(CHECKPOINT_DIR, "best.pt")
    if not os.path.exists(checkpoint_path):
        print("Error: No checkpoint found to export!")
        return

    model.load_state_dict(torch.load(checkpoint_path))
    model.to('cpu') 
    model.eval()

    # Create dummy input
    dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE)
    onnx_file_path = os.path.join(RESULTS_DIR, "wafer_defect_model.onnx")

    # Export using the Torch-to-ONNX Legacy pathway (widely compatible)
    # We specify opset_version=12 or 13 for better compatibility
    torch.onnx.export(
        model,
        dummy_input,
        onnx_file_path,
        export_params=True,
        opset_version=13,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )

    if os.path.exists(onnx_file_path):
        print(f"SUCCESS: Model saved to {onnx_file_path}")
        
        # Verify
        check_model = onnx.load(onnx_file_path)
        onnx.checker.check_model(check_model)
        print("ONNX verification passed!")
        
        # Download
        files.download(onnx_file_path)
    else:
        print("Export failed.")

export_to_onnx()
